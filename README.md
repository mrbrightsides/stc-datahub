# STC DataHub ğŸ“ˆ

STC DataHub adalah platform standalone untuk discover, fetch, scrape, normalize, dan store dataset pariwisata dari berbagai sumber.
Tujuan utamanya adalah menyediakan hub data yang bisa diperluas lewat sistem connector-driven, sehingga dataset baru bisa ditambahkan tanpa perlu mengubah kode utama.

[![Build Status](https://img.shields.io/badge/build-passing-brightgreen)](https://github.com/mrbrightsides/stc-datahub/actions)
[![Docker](https://img.shields.io/badge/docker-ready-blue)](https://hub.docker.com/r/elpeef/stc-datahub)
[![Python](https://img.shields.io/badge/python-3.10%2B-yellow)](https://www.python.org/)
[![React](https://img.shields.io/badge/frontend-react-blueviolet)](https://reactjs.org/)
[![License: MIT](https://img.shields.io/badge/license-MIT-lightgrey.svg)](LICENSE)
[![Data Sources](https://img.shields.io/badge/data-kaggle%20%7C%20garuda%20%7C%20osm-orange)](https://github.com/mrbrightsides/stc-datahub)

> ğŸ’¡ MVP ini fokus pada reliability, provenance, dan kemudahan menambah konektor.

---

## âœ¨ Features

- ğŸ”Œ Connector-driven architecture (Kaggle, CSV/JSON, HTML, XHR, OSM, Airbnb, dsb).

- ğŸ“¦ Data pipeline: Fetch â†’ Validate â†’ Normalize â†’ Enrich â†’ Store â†’ Provenance Log.

- ğŸ—‚ï¸ Multi-format output: CSV, NDJSON, Parquet.

- ğŸ”„ Versioning: snapshot raw data + mapping history.

- ğŸ‘©â€ğŸ’» Admin UI: register source, mapping schema, scheduling, preview 100 rows.

- âš–ï¸ Legal & safe: robots.txt check, TOS/license stored, polite crawling.

- ğŸŒ API ready: FastAPI backend with OpenAPI docs.

- ğŸ³ Dockerized stack: deploy with docker-compose up.

---

## ğŸ—ï¸ Tech Stack

- Backend: Python (FastAPI)

- Frontend: React (Vite/Next.js optional)

- Database: PostgreSQL (or DuckDB for quick local runs)

- Object Storage: S3-compatible (e.g. MinIO, AWS S3)

- Queue: Redis

- Orchestration: Docker Compose

---

## ğŸ”Œ Example Connectors (MVP)

- Kaggle â†’ via Kaggle API (kaggle.json auth).

- Generic HTTP â†’ download direct CSV/JSON.

- HTML Scraper â†’ requests + BeautifulSoup, dengan robots.txt check.

- XHR/JSON â†’ auto-detect JSON endpoints dari halaman.

- OpenStreetMap â†’ POI pull via Overpass API.

- Garuda (Kemdikbud) â†’ pencarian dataset publikasi pariwisata.

---

## âš™ï¸ Pipeline

```mermaid
flowchart TD
    A["Register Source"] --> B["Fetch"]
    B --> C["Validate robots.txt & License"]
    C --> D["Normalize via Mapping Template"]
    D --> E["Enrich Web3 Fields (optional)"]
    E --> F["Store Raw + Normalized"]
    F --> G["Provenance Log"]
    G --> H["Preview & Download"]
```

```mermaid
flowchart TD
    A[ğŸ‘©â€ğŸ’» Users\nResearchers / Devs / Communities] --> B[ğŸ“Š STC DataHub\nDiscover Â· Fetch Â· Normalize Â· Store]
    C[Kaggle\nGov Portals\ndata.go.id] --> B
    D[Garuda Kemdikbud\nAcademic Repos] --> B
    E[OpenStreetMap\nInsideAirbnb\nOther APIs] --> B
    B --> F[ğŸ“ˆ Analytics & Insights\nDashboards, Reports]
    B --> G[ğŸ“ Research & Education\nOpen Data for Academia]
    B --> H[ğŸŒ Web3 Ecosystem\nSmart Contracts, dApps, NFT Tourism]
```

---

## ğŸ“‚ Project Structure

```bash
stc-datahub/
â”‚â”€â”€ backend/          # FastAPI + connectors
â”‚   â”œâ”€â”€ connectors/
â”‚   â”‚   â”œâ”€â”€ kaggle.py
â”‚   â”‚   â”œâ”€â”€ http_csv.py
â”‚   â”‚   â”œâ”€â”€ html_scraper.py
â”‚   â”‚   â”œâ”€â”€ xhr_json.py
â”‚   â”‚   â””â”€â”€ osm.py
â”‚   â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ api/
â”‚   â””â”€â”€ main.py
â”‚
â”‚â”€â”€ frontend/         # React (Vite/Next.js optional)
â”‚   â””â”€â”€ src/
â”‚
â”‚â”€â”€ storage/          # Raw + normalized data
â”‚â”€â”€ docker-compose.yml
â”‚â”€â”€ .env.example
â”‚â”€â”€ README.md
```

---

## ğŸš€ Quick Start

1. Clone repo:
```bash
git clone https://github.com/elpeef/stc-datahub.git
cd stc-datahub
```

2. Copy env:
```bash
cp .env.example .env
```

3. Run with Docker:
```bash
docker-compose up --build
```

4. Access services:

- FastAPI docs â†’ http://localhost:8000/docs

- React Admin UI â†’ http://localhost:3000

---

## ğŸ“ Roadmap (MVP â†’ Extended)

- Kaggle connector

- Garuda HTML search connector

- Generic HTTP CSV/JSON connector

- Admin UI for dataset mapping

- Scheduling via cron

- Selenium connector for JS-heavy sites

- SIWE (Sign-In with Ethereum) for secure dataset access

---

## ğŸ“œ License

MIT License. Dataset usage subject to respective source licenses.
